#!/usr/bin/env python3
"""
–ü–æ–ª–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ WWM (Multi-file –≤–µ—Ä—Å–∏—è)
–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ ‚Üí –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ ‚Üí –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞ ‚Üí –ó–∞–ø–µ–∫–∞–Ω—å–µ .dat —Ñ–∞–π–ª–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –∏–≥—Ä—ã —Å –æ–¥–Ω–∏–º –æ–±—â–∏–º –ø–µ—Ä–µ–≤–æ–¥–æ–º
–ì–æ—Ç–æ–≤–æ –¥–ª—è CI/CD –∏ GitHub —Ä–µ–ª–∏–∑–æ–≤!
"""

import argparse
import os
import sys
import struct
import pyzstd
import csv
import re


def log(msg):
    print(f"[WWM] {msg}")


def extract_file(input_file, output_dir):
    try:
        base_name = os.path.splitext(os.path.basename(input_file))[0]
        output_subdir = os.path.join(output_dir, base_name)
        os.makedirs(output_subdir, exist_ok=True)

        with open(input_file, 'rb') as f:
            if f.read(4) != b'\xEF\xBE\xAD\xDE':
                log(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {input_file}")
                return False

            f.read(4)
            offset_count_bytes = f.read(4)
            offset_count = struct.unpack('<I', offset_count_bytes)[0] + 1

            if offset_count == 1:
                comp_block_len = struct.unpack('<I', f.read(4))[0]
                comp_block = f.read(comp_block_len)

                if len(comp_block) < comp_block_len:
                    return False

                header = comp_block[:9]
                comp_data_part = comp_block[9:]

                if len(header) < 9:
                    return False
                    
                comp_type, comp_size, decomp_size = struct.unpack('<BII', header)

                if comp_type == 0x04:
                    try:
                        decomp_data = pyzstd.decompress(comp_data_part)
                        output_path = os.path.join(output_subdir, f"{base_name}_0.dat")
                        with open(output_path, 'wb') as outf:
                            outf.write(decomp_data)
                    except Exception as e:
                        log(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –±–ª–æ–∫–∞ 0: {e}")
            else:
                offsets = [struct.unpack('<I', f.read(4))[0] for _ in range(offset_count)]
                data_start = f.tell()
                
                for i in range(offset_count):
                    current_offset = offsets[i]
                    
                    if i == (offset_count - 1):
                        continue
                    
                    next_offset = offsets[i + 1]
                    block_len = next_offset - current_offset

                    f.seek(data_start + current_offset)
                    comp_block = f.read(block_len)

                    if len(comp_block) < block_len:
                        continue

                    if len(comp_block) < 9:
                        continue

                    header = comp_block[:9]
                    comp_data_part = comp_block[9:]
                    comp_type, comp_size, decomp_size = struct.unpack('<BII', header)
                    
                    if comp_type == 0x04:
                        try:
                            decomp_data = pyzstd.decompress(comp_data_part)
                            output_path = os.path.join(output_subdir, f"{base_name}_{i}.dat")
                            with open(output_path, 'wb') as outf:
                                outf.write(decomp_data)
                        except Exception as e:
                            log(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –±–ª–æ–∫–∞ {i}: {e}")

            log(f"‚úÖ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {output_subdir}")
            return output_subdir

    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏: {e}")
        import traceback
        traceback.print_exc()
        return False


def extract_text(input_dir, output_dir, file_prefix):
    try:
        output_path = os.path.join(output_dir, f"TextExtractor_{file_prefix}.csv")
        
        if os.path.exists(output_path):
            os.remove(output_path)
            log(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {output_path}")
        
        with open(output_path, 'w', encoding='utf-8', newline='') as outf:
            writer = csv.writer(outf, delimiter=';')
            writer.writerow(["Number", "File", "All Blocks", "Work Blocks", "Current Block", "Unknown", "ID", "OriginalText"])
            
            k = 0
            for filename in sorted(os.listdir(input_dir)):
                if not filename.endswith('.dat'):
                    continue
                
                if filename.endswith('_0.dat'):
                    log(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –±–ª–æ–∫: {filename}")
                    continue
                
                full_path = os.path.join(input_dir, filename)
                
                try:
                    with open(full_path, 'rb') as f:
                        f.seek(0)
                        count_full = struct.unpack('<I', f.read(4))[0]
                        f.read(4)
                        count_text = struct.unpack('<I', f.read(4))[0]
                        f.read(12)
                        code = f.read(count_full).hex()
                        f.read(17)
                        data_start = f.tell()
                        
                        for i in range(count_full):
                            f.seek(data_start + (i * 16))
                            id_bytes = f.read(8).hex()
                            start_text_offset = f.tell()
                            offset_text = struct.unpack('<I', f.read(4))[0]
                            length = struct.unpack('<I', f.read(4))[0]
                            
                            f.seek(start_text_offset + offset_text)
                            text = f.read(length).decode('utf-8', errors='ignore')
                            
                            text = text.replace('\n', '\\n')
                            text = text.replace('\r', '\\r')
                            
                            k += 1
                            writer.writerow([str(k), filename, count_full, count_text, str(i), code[i*2:(i+1)*2], id_bytes, text])
                except Exception as e:
                    log(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {filename}: {e}")
                    continue
        
        log(f"‚úÖ –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {output_path} ({k} –∑–∞–ø–∏—Å–µ–π)")
        return output_path
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return None


def apply_translation(tsv_path, csv_path, output_csv_path):
    try:
        translations = {}
        with open(tsv_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f, delimiter='\t')
            next(reader, None)
            for row in reader:
                if len(row) >= 2:
                    translations[row[0].strip()] = row[1].strip()
        
        log(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {len(translations)}")
        
        replaced = 0
        total = 0
        with open(csv_path, 'r', encoding='utf-8', newline='') as src, \
             open(output_csv_path, 'w', encoding='utf-8', newline='') as out:
            
            reader = csv.reader(src, delimiter=';')
            writer = csv.writer(out, delimiter=';')
            
            header = next(reader)
            writer.writerow(header)
            
            id_idx = header.index('ID')
            text_idx = header.index('OriginalText')
            
            for row in reader:
                if len(row) <= max(id_idx, text_idx):
                    writer.writerow(row)
                    continue
                
                total += 1
                id_val = row[id_idx].strip()
                
                if id_val in translations:
                    row[text_idx] = translations[id_val]
                    replaced += 1
                
                writer.writerow(row)
        
        log(f"‚úÖ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {replaced} –∏–∑ {total}")
        return True
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return False


def pak_text(csv_path, extract_dir):
    try:
        with open(csv_path, 'r', encoding='utf-8', newline='') as f:
            reader = csv.reader(f, delimiter=';')
            header = next(reader)
            
            id_idx = header.index('ID')
            file_idx = header.index('File')
            text_idx = header.index('OriginalText')
            all_blocks_idx = header.index('All Blocks')
            work_blocks_idx = header.index('Work Blocks')
            unknown_idx = header.index('Unknown')
            
            base_name = ''
            start_unk = 0
            start_id = 0
            curr_text = 0
            all_blocks = b''
            work_blocks = b''
            file_bytes = b'\xDC\x96\x58\x59\x00\x00\x00\x00'
            filled_bytes_unk = b''
            filled_bytes_id = b''
            filled_bytes_text = b''
            
            for row in reader:
                if row[0] == 'Number' or row[0] == '':
                    continue
                
                file_name = row[file_idx]
                
                if file_name.endswith('_0.dat'):
                    log(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞: {file_name}")
                    continue
                
                if file_name != base_name:
                    if base_name != '':
                        output_path = os.path.join(extract_dir, base_name)
                        with open(output_path, 'wb') as outf:
                            outf.write(all_blocks)
                            outf.write(work_blocks)
                            outf.write(file_bytes)
                            outf.write(filled_bytes_unk)
                            outf.write(filled_bytes_id)
                            outf.write(filled_bytes_text)
                    
                    base_name = str(file_name)
                    all_blocks = struct.pack('<II', int(row[all_blocks_idx]), 0)
                    work_blocks = struct.pack('<II', int(row[work_blocks_idx]), 0)
                    file_bytes = b'\xDC\x96\x58\x59\x00\x00\x00\x00'
                    filled_bytes_unk = b''
                    filled_bytes_id = b''
                    filled_bytes_text = b''
                    
                    start_unk = len(all_blocks) + len(work_blocks) + len(file_bytes)
                    start_id = start_unk + int(row[all_blocks_idx]) + 17
                    curr_text = start_id + int(row[all_blocks_idx]) * 16
                
                text = row[text_idx].replace('\\n', '\x0A').encode('utf-8')
                
                unk_byte = bytes.fromhex(row[unknown_idx])
                filled_bytes_unk += unk_byte
                start_unk += 1
                
                if start_unk >= int(row[all_blocks_idx]) + 24:
                    if len(filled_bytes_unk) >= 16:
                        filled_bytes_unk += b'\xFF' + filled_bytes_unk[:16]
                    else:
                        filled_bytes_unk += b'\xFF' + filled_bytes_unk + b'\x80' * (16 - len(filled_bytes_unk))
                
                id_byte = bytes.fromhex(row[id_idx])
                filled_bytes_id += id_byte
                start_id += 8
                
                offset_len = struct.pack('<II', (curr_text - start_id), len(text))
                filled_bytes_id += offset_len
                start_id += 8
                
                filled_bytes_text += text
                curr_text += len(text)
            
            if base_name != '':
                output_path = os.path.join(extract_dir, base_name)
                with open(output_path, 'wb') as outf:
                    outf.write(all_blocks)
                    outf.write(work_blocks)
                    outf.write(file_bytes)
                    outf.write(filled_bytes_unk)
                    outf.write(filled_bytes_id)
                    outf.write(filled_bytes_text)
        
        return True
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–µ–∫–∞–Ω—å—è: {e}")
        import traceback
        traceback.print_exc()
        return False


def pak_file(dat_folder, output_file):
    try:
        files = [f for f in os.listdir(dat_folder) if f.endswith('.dat')]
        
        def extract_number(filename):
            match = re.search(r'(\d+)\.dat$', filename)
            return int(match.group(1)) if match else float('inf')
        
        files.sort(key=extract_number)
        
        log(f"üîç –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏: {len(files)}")
        
        with open(output_file, 'wb') as outfile:
            # 1. –ó–∞–≥–æ–ª–æ–≤–æ–∫ + –≤–µ—Ä—Å–∏—è
            outfile.write(b'\xEF\xBE\xAD\xDE\x01\x00\x00\x00')
            
            outfile.write(struct.pack('<I', len(files) - 1))
            
            # –°–æ–±–∏—Ä–∞–µ–º –∞—Ä—Ö–∏–≤ –≤ –ø–∞–º—è—Ç–∏
            archive = b''
            for filename in files:
                file_path = os.path.join(dat_folder, filename)
                
                with open(file_path, 'rb') as infile:
                    data = infile.read()
                
                # –ü–∏—à–µ–º —Å–º–µ—â–µ–Ω–∏–µ –¢–ï–ö–£–©–ï–ì–û —Ñ–∞–π–ª–∞ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ)
                if filename != files[-1]:
                    outfile.write(struct.pack('<I', len(archive)))
                
                # –°–∂–∏–º–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∞—Ä—Ö–∏–≤
                comp_data = pyzstd.compress(data)
                header = struct.pack('<BII', 4, len(comp_data), len(data))
                archive += header + comp_data
            
            outfile.write(struct.pack('<I', len(archive)))
            
            outfile.write(archive)
        
        log(f"‚úÖ –°–±–æ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£–ø–∞–∫–æ–≤–∞–Ω–æ: {len(files)} –±–ª–æ–∫–æ–≤")
        log(f"‚úÖ –†–∞–∑–º–µ—Ä –∞—Ä—Ö–∏–≤–∞: {len(archive)} –±–∞–π—Ç")
        log(f"‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫: {output_file}")
        return True
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —É–ø–∞–∫–æ–≤–∫–∏: {e}")
        import traceback
        traceback.print_exc()
        return False


def process_game_file(input_file, translation_file, work_dir, output_dir):
    base_name = os.path.splitext(os.path.basename(input_file))[0]
    
    log(f"\n{'='*50}")
    log(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {base_name}")
    log(f"{'='*50}")
    
    log(f"\n[–†–∞—Å–ø–∞–∫–æ–≤–∫–∞] {base_name}...")
    extract_dir = os.path.join(work_dir, base_name)
    if not extract_file(input_file, work_dir):
        return False
    
    log(f"\n[–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ] –¢–µ–∫—Å—Ç–æ–≤ –∏–∑ {base_name}...")
    csv_path = extract_text(extract_dir, work_dir, base_name)
    if not csv_path:
        return False
    
    log(f"\n[–ü–µ—Ä–µ–≤–æ–¥] –ü—Ä–∏–º–µ–Ω—è—é –ø–µ—Ä–µ–≤–æ–¥ –∫ {base_name}...")
    translated_csv = os.path.join(work_dir, f"TextExtractor_{base_name}_translated.csv")
    if not apply_translation(translation_file, csv_path, translated_csv):
        return False
    
    log(f"\n[–ó–∞–ø–µ–∫–∞–Ω—å–µ] –¢–µ–∫—Å—Ç–æ–≤ –¥–ª—è {base_name}...")
    if not pak_text(translated_csv, extract_dir):
        return False
    
    log(f"\n[–£–ø–∞–∫–æ–≤–∫–∞] –§–∏–Ω–∞–ª—å–Ω–∞—è —É–ø–∞–∫–æ–≤–∫–∞ {base_name}...")
    output_file = os.path.join(output_dir, f"{base_name}")
    if not pak_file(extract_dir, output_file):
        return False
    
    log(f"\n‚úÖ {base_name} –≥–æ—Ç–æ–≤!")
    return True


def main():
    parser = argparse.ArgumentParser(description='WWM Translation Builder - Multi-file Pipeline')
    parser.add_argument('--input', '-i', nargs='+', required=True, 
                       help='–í—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–≥—Ä—ã (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ: file1 file2)')
    parser.add_argument('--translation', '-t', required=True, help='TSV –ø–µ—Ä–µ–≤–æ–¥ (ID\\tTranslation)')
    parser.add_argument('--output', '-o', default='release/', help='–í—ã—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞ –¥–ª—è —Ä–µ–ª–∏–∑–∞ (.bin —Ñ–∞–π–ª—ã)')
    parser.add_argument('--workdir', '-w', default='work/', help='–†–∞–±–æ—á–∞—è –ø–∞–ø–∫–∞ (–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã)')
    
    args = parser.parse_args()
    
    os.makedirs(args.output, exist_ok=True)
    os.makedirs(args.workdir, exist_ok=True)
    
    log("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
    log("üì¶ WWM Translation Builder (Multi-file Pipeline)")
    log(f"üìÅ –§–∞–π–ª—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(args.input)}")
    log("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
    
    for input_file in args.input:
        if not os.path.exists(input_file):
            log(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_file}")
            return 1
    
    if not os.path.exists(args.translation):
        log(f"‚ùå –§–∞–π–ª –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.translation}")
        return 1
    
    failed_files = []
    for input_file in args.input:
        if not process_game_file(input_file, args.translation, args.workdir, args.output):
            failed_files.append(input_file)
    
    log("\n" + "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
    log("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–Å–¢")
    log("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
    
    success_count = len(args.input) - len(failed_files)
    log(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {success_count}/{len(args.input)}")
    
    if failed_files:
        log(f"‚ùå –û—à–∏–±–∫–∏ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ:")
        for f in failed_files:
            log(f"   - {f}")
        return 1
    
    log(f"\nüìÅ –ì–æ—Ç–æ–≤—ã–µ .bin —Ñ–∞–π–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤: {args.output}")
    log("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
    return 0


if __name__ == '__main__':
    sys.exit(main())
