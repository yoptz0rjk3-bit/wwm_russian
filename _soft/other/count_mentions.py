#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–º–µ–Ω –∏–∑ dictionary.tsv –≤ translation_en.tsv
–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ç—Ä–µ—Ç–∏–π —Å—Ç–æ–ª–±–µ—Ü dictionary.tsv
"""

import re
import sys
from pathlib import Path
from collections import defaultdict


def load_names_from_dictionary(dict_path: str) -> list[tuple[str, int]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–º–µ–Ω–∞ –∏–∑ dictionary.tsv –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ (–∏–º—è, –Ω–æ–º–µ—Ä_—Å—Ç—Ä–æ–∫–∏)."""
    names = []
    with open(dict_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        for i, line in enumerate(lines[1:], start=2):
            line = line.rstrip('\n\r')
            if not line:
                continue
            parts = line.split('\t')
            if len(parts) >= 1:
                original_name = parts[0].strip()
                if original_name:
                    names.append((original_name, i))
    return names


def load_texts_from_translation(translation_path: str) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –∏–∑ translation_en.tsv –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø–æ–∏—Å–∫–∞."""
    all_text_parts = []
    id_pattern = re.compile(r'^[0-9a-f]{16}$')
    
    with open(translation_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        current_entry = []
        
        for line in lines[1:]:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            line = line.rstrip('\n\r')
            if not line:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å ID (16 hex —Å–∏–º–≤–æ–ª–æ–≤)
            parts = line.split('\t', 1)
            if len(parts) >= 1 and id_pattern.match(parts[0]):
                # –ù–æ–≤–∞—è –∑–∞–ø–∏—Å—å - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é
                if current_entry:
                    entry_text = ' '.join(current_entry)
                    all_text_parts.append(entry_text)
                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                if len(parts) >= 2:
                    current_entry = [parts[1]]
                else:
                    current_entry = []
            else:
                # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∑–∞–ø–∏—Å–∏
                if current_entry:
                    current_entry.append(line)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å
        if current_entry:
            entry_text = ' '.join(current_entry)
            all_text_parts.append(entry_text)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –¥–ª—è –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    return ' '.join(all_text_parts)


def count_mentions(name: str, all_text: str) -> int:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–º–µ–Ω–∏ –≤ —Ç–µ–∫—Å—Ç–µ.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–∏—Å–∫ —Å —É—á–µ—Ç–æ–º –≥—Ä–∞–Ω–∏—Ü —Å–ª–æ–≤, —á—Ç–æ–±—ã –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—å —á–∞—Å—Ç–∏ —Å–ª–æ–≤.
    –£—á–∏—Ç—ã–≤–∞–µ—Ç –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã –∏ –¥–µ—Ñ–∏—Å—ã –∫–∞–∫ —á–∞—Å—Ç—å –∏–º–µ–Ω–∏.
    """
    # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –µ—Å–ª–∏ –∏–º—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–µ–∫—Å—Ç–µ –≤–æ–æ–±—â–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
    if name.lower() not in all_text.lower():
        return 0
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è regex
    escaped_name = re.escape(name)
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω, –∫–æ—Ç–æ—Ä—ã–π –∏—â–µ—Ç –∏–º—è –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ
    # –£—á–∏—Ç—ã–≤–∞–µ–º, —á—Ç–æ –ø–µ—Ä–µ–¥ –∏ –ø–æ—Å–ª–µ –∏–º–µ–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å:
    # - –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤ (\b)
    # - –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã (–¥–ª—è —Å–ª—É—á–∞–µ–≤ —Ç–∏–ø–∞ "Sun Mengliang's")
    # - –¥–µ—Ñ–∏—Å—ã (–¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –∏–º–µ–Ω)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π lookbehind –∏ lookahead –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    # –ò—â–µ–º –∏–º—è, –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —á–∞—Å—Ç—å—é –¥—Ä—É–≥–æ–≥–æ —Å–ª–æ–≤–∞
    
    # –ï—Å–ª–∏ –∏–º—è —Å–æ–¥–µ—Ä–∂–∏—Ç –∞–ø–æ—Å—Ç—Ä–æ—Ñ –∏–ª–∏ –¥–µ—Ñ–∏—Å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –≥–∏–±–∫–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω
    if "'" in name or "-" in name:
        # –î–ª—è –∏–º–µ–Ω —Å –∞–ø–æ—Å—Ç—Ä–æ—Ñ–∞–º–∏/–¥–µ—Ñ–∏—Å–∞–º–∏ –∏—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏
        # –Ω–æ —Ä–∞–∑—Ä–µ—à–∞–µ–º –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã –∏ –¥–µ—Ñ–∏—Å—ã –∫–∞–∫ —á–∞—Å—Ç—å –∏–º–µ–Ω–∏
        pattern = r'(?<![A-Za-z])' + escaped_name + r'(?![A-Za-z])'
    else:
        # –î–ª—è –æ–±—ã—á–Ω—ã—Ö –∏–º–µ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤
        pattern = r'\b' + escaped_name + r'\b'
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è (–±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
    matches = re.findall(pattern, all_text, re.IGNORECASE)
    return len(matches)


def update_dictionary_with_counts(dict_path: str, name_counts: dict[str, int], name_lines: dict[str, int]) -> None:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç dictionary.tsv, –¥–æ–±–∞–≤–ª—è—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤ —Ç—Ä–µ—Ç–∏–π —Å—Ç–æ–ª–±–µ—Ü."""
    # –ß–∏—Ç–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏
    with open(dict_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏
    updated_lines = []
    for i, line in enumerate(lines):
        line = line.rstrip('\n\r')
        if i == 0:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ - –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç—Ä–µ—Ç–∏–π —Å—Ç–æ–ª–±–µ—Ü
            parts = line.split('\t')
            if len(parts) < 3 or not parts[2].strip():
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç—Ä–µ—Ç—å–µ–≥–æ —Å—Ç–æ–ª–±—Ü–∞
                if len(parts) >= 2:
                    updated_lines.append(f"{parts[0]}\t{parts[1]}\t–£–ø–æ–º–∏–Ω–∞–Ω–∏—è\n")
                else:
                    updated_lines.append(f"{parts[0]}\t\t–£–ø–æ–º–∏–Ω–∞–Ω–∏—è\n")
            else:
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —É–∂–µ –µ—Å—Ç—å
                updated_lines.append(line + '\n')
        else:
            parts = line.split('\t')
            if len(parts) >= 1:
                original_name = parts[0].strip()
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
                count = name_counts.get(original_name, 0)
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
                if len(parts) >= 2:
                    # –ï—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥
                    translation = parts[1]
                    # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å —Ç—Ä–µ—Ç–∏–π —Å—Ç–æ–ª–±–µ—Ü, –∑–∞–º–µ–Ω—è–µ–º –µ–≥–æ
                    if len(parts) >= 3:
                        new_line = f"{original_name}\t{translation}\t{count}\n"
                    else:
                        new_line = f"{original_name}\t{translation}\t{count}\n"
                else:
                    # –ù–µ—Ç –ø–µ—Ä–µ–≤–æ–¥–∞
                    new_line = f"{original_name}\t\t{count}\n"
                
                updated_lines.append(new_line)
            else:
                # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è
                updated_lines.append(line + '\n')
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
    with open(dict_path, 'w', encoding='utf-8') as f:
        f.writelines(updated_lines)


def main():
    dict_path = 'docs/dictionary.tsv'
    translation_path = 'translation_en.tsv'
    
    print("üìñ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–º–µ–Ω –∏–∑ dictionary.tsv...")
    names_with_lines = load_names_from_dictionary(dict_path)
    print(f"   –ù–∞–π–¥–µ–Ω–æ –∏–º–µ–Ω: {len(names_with_lines)}")
    
    print("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ translation_en.tsv...")
    all_text = load_texts_from_translation(translation_path)
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–µ–∫—Å—Ç–∞: {len(all_text)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    print("üîç –ü–æ–¥—Å—á–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–π...")
    name_counts = {}
    name_lines = {}
    found_count = 0
    total_names = len(names_with_lines)
    
    for idx, (name, line_num) in enumerate(names_with_lines, 1):
        name_lines[name] = line_num
        count = count_mentions(name, all_text)
        name_counts[name] = count
        if count > 0:
            found_count += 1
            if found_count <= 20:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 20 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
                print(f"   {name}: {count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π", flush=True)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 –∏–º–µ–Ω
        if idx % 100 == 0 or idx == total_names:
            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx}/{total_names} –∏–º–µ–Ω ({idx*100//total_names}%)", flush=True)
    
    if found_count > 20:
        print(f"   ... –∏ –µ—â–µ {found_count - 20} –∏–º–µ–Ω —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏—è–º–∏")
    
    print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥–ª—è {found_count} –∏–º–µ–Ω")
    print(f"   –í—Å–µ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π: {sum(name_counts.values())}")
    
    print(f"\nüíæ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ {dict_path}...")
    update_dictionary_with_counts(dict_path, name_counts, name_lines)
    print("‚úÖ –ì–æ—Ç–æ–≤–æ!")


if __name__ == '__main__':
    main()

